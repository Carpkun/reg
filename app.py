# SQLite3 í˜¸í™˜ì„± íŒ¨ì¹˜ (Streamlit Cloudìš©)
import sys
try:
    import pysqlite3
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
except ImportError:
    pass

import streamlit as st
import os
import hashlib
import json
from dotenv import load_dotenv
from typing import List, Dict
import time
from openai import OpenAI
import google.generativeai as genai

from document_processor import DocumentProcessor
from vector_store import VectorStore

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì¶˜ì²œë¬¸í™”ì› ê·œì • ê²€ìƒ‰ ì‹œìŠ¤í…œ",
    page_icon="ğŸ“‹",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼ (ìµœì†Œí•œìœ¼ë¡œ ê°„ì†Œí™”)
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #1e3a8a, #3b82f6);
        padding: 1rem;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .main-header h1 {
        color: white;
        text-align: center;
        margin: 0;
    }
</style>
""", unsafe_allow_html=True)

def get_documents_hash(data_folder: str = "./data") -> str:
    """data í´ë”ì˜ ë¬¸ì„œë“¤ë¡œë¶€í„° í•´ì‹œê°’ ìƒì„±"""
    if not os.path.exists(data_folder):
        return ""
    
    docx_files = [f for f in os.listdir(data_folder) if f.endswith('.docx')]
    if not docx_files:
        return ""
    
    # íŒŒì¼ëª…ê³¼ ìˆ˜ì •ì‹œê°„ì„ ì¡°í•©í•´ì„œ í•´ì‹œ ìƒì„±
    file_info = []
    for filename in sorted(docx_files):
        file_path = os.path.join(data_folder, filename)
        mtime = os.path.getmtime(file_path)
        file_info.append(f"{filename}:{mtime}")
    
    content = "|".join(file_info)
    return hashlib.md5(content.encode()).hexdigest()

def is_vectorstore_up_to_date() -> bool:
    """ë²¡í„° ìŠ¤í† ì–´ê°€ ìµœì‹  ìƒíƒœì¸ì§€ í™•ì¸"""
    hash_file = "./chroma_db/documents_hash.json"
    current_hash = get_documents_hash()
    
    if not os.path.exists(hash_file):
        return False
    
    try:
        with open(hash_file, 'r') as f:
            saved_data = json.load(f)
            return saved_data.get('hash') == current_hash
    except:
        return False

def save_documents_hash():
    """í˜„ì¬ ë¬¸ì„œ í•´ì‹œë¥¼ ì €ì¥"""
    hash_file = "./chroma_db/documents_hash.json"
    current_hash = get_documents_hash()
    
    os.makedirs("./chroma_db", exist_ok=True)
    with open(hash_file, 'w') as f:
        json.dump({'hash': current_hash}, f)

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'vector_store' not in st.session_state:
        st.session_state.vector_store = None
    if 'document_processor' not in st.session_state:
        st.session_state.document_processor = DocumentProcessor()
    if 'openai_client' not in st.session_state:
        st.session_state.openai_client = None
    if 'gemini_model' not in st.session_state:
        st.session_state.gemini_model = None
    if 'indexed_documents' not in st.session_state:
        st.session_state.indexed_documents = False
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []

def check_api_keys():
    """API í‚¤ í™•ì¸ ë° ì„¤ì •"""
    openai_api_key = os.getenv('OPENAI_API_KEY')
    google_api_key = os.getenv('GOOGLE_API_KEY')
    
    missing_keys = []
    
    if not openai_api_key or openai_api_key == 'your_openai_api_key_here':
        missing_keys.append("OpenAI")
    
    if not google_api_key or google_api_key == 'your_google_api_key_here':
        missing_keys.append("Google")
    
    if missing_keys:
        st.error(f"âš ï¸ {', '.join(missing_keys)} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.info("""
        **API í‚¤ ì„¤ì • ë°©ë²•:**
        1. `.env` íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ ì…ë ¥í•˜ì„¸ìš”:
        ```
        OPENAI_API_KEY=your_actual_openai_api_key_here
        GOOGLE_API_KEY=your_actual_google_api_key_here
        ```
        2. OpenAI API í‚¤: https://platform.openai.com/api-keys
        3. Google AI Studio API í‚¤: https://aistudio.google.com/app/apikey
        """)
        return None, None
    
    return openai_api_key, google_api_key

def initialize_components(openai_api_key: str, google_api_key: str):
    """ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”"""
    try:
        st.write("ğŸ” [DEBUG] initialize_components ì‹œì‘")
        
        if st.session_state.vector_store is None:
            st.write("ğŸ” [DEBUG] VectorStore ìƒì„± ì‹œì‘")
            st.write(f"ğŸ” [DEBUG] OpenAI API í‚¤ ì¡´ì¬: {bool(openai_api_key)}")
            st.write(f"ğŸ” [DEBUG] OpenAI API í‚¤ ê¸¸ì´: {len(openai_api_key) if openai_api_key else 0}")
            
            try:
                # VectorStore ìƒì„± ì‹œë„
                st.write("ğŸ” [DEBUG] VectorStore ê°ì²´ ìƒì„± ì‹œë„...")
                vector_store = VectorStore(openai_api_key=openai_api_key)
                st.write("âœ… [SUCCESS] VectorStore ê°ì²´ ìƒì„± ì™„ë£Œ")
                st.session_state.vector_store = vector_store
                st.write("âœ… [SUCCESS] VectorStore ì„¸ì…˜ ìƒíƒœì— ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                st.error(f"âŒ [ERROR] VectorStore ìƒì„± ì‹¤íŒ¨: {str(e)}")
                st.write(f"ğŸ” [DEBUG] VectorStore ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
                st.write(f"ğŸ” [DEBUG] VectorStore ì˜¤ë¥˜ ìƒì„¸: {e}")
                import traceback
                st.code(traceback.format_exc())
                return False
        else:
            st.write("â„¹ï¸ [INFO] ê¸°ì¡´ VectorStore ì‚¬ìš©")
        
        if st.session_state.openai_client is None:
            st.write("ğŸ” [DEBUG] OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹œì‘")
            try:
                st.session_state.openai_client = OpenAI(api_key=openai_api_key)
                st.write("âœ… [SUCCESS] OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì™„ë£Œ")
            except Exception as e:
                st.error(f"âŒ [ERROR] OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
                return False
        else:
            st.write("â„¹ï¸ [INFO] ê¸°ì¡´ OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©")
        
        if st.session_state.gemini_model is None:
            st.write("ğŸ” [DEBUG] Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹œì‘")
            try:
                genai.configure(api_key=google_api_key)
                st.session_state.gemini_model = genai.GenerativeModel('gemini-2.0-flash')
                st.write("âœ… [SUCCESS] Gemini ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                st.error(f"âŒ [ERROR] Gemini ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
                return False
        else:
            st.write("â„¹ï¸ [INFO] ê¸°ì¡´ Gemini ëª¨ë¸ ì‚¬ìš©")
        
        st.write("ğŸ‰ [SUCCESS] ëª¨ë“  ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        return True
    except Exception as e:
        st.error(f"âŒ [ERROR] ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì „ì²´ ì˜¤ë¥˜: {str(e)}")
        st.write(f"ğŸ” [DEBUG] ì „ì²´ ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        import traceback
        st.code(traceback.format_exc())
        return False

def index_documents():
    """ë¬¸ì„œ ì¸ë±ì‹± ì‹¤í–‰"""
    with st.spinner("ë¬¸ì„œë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # ë””ë²„ê¹…: íŒŒì¼ ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        import os
        st.write(f"ğŸ” í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬: {os.getcwd()}")
        
        data_path = "./data"
        st.write(f"ğŸ” data í´ë” ê²½ë¡œ: {os.path.abspath(data_path)}")
        st.write(f"ğŸ” data í´ë” ì¡´ì¬ ì—¬ë¶€: {os.path.exists(data_path)}")
        
        if os.path.exists(data_path):
            files = os.listdir(data_path)
            docx_files = [f for f in files if f.endswith('.docx')]
            st.write(f"ğŸ” data í´ë” ë‚´ ì „ì²´ íŒŒì¼ ìˆ˜: {len(files)}")
            st.write(f"ğŸ” data í´ë” ë‚´ docx íŒŒì¼ ìˆ˜: {len(docx_files)}")
            if docx_files:
                st.write(f"ğŸ” ì²« ë²ˆì§¸ docx íŒŒì¼: {docx_files[0]}")
        else:
            st.error(f"âŒ data í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {os.path.abspath(data_path)}")
            return False
        
        # ë¬¸ì„œ ì²˜ë¦¬
        try:
            documents = st.session_state.document_processor.process_documents(data_path)
            st.write(f"ğŸ” ì²˜ë¦¬ëœ ë¬¸ì„œ ì²­í¬ ìˆ˜: {len(documents) if documents else 0}")
        except Exception as e:
            st.error(f"âŒ ë¬¸ì„œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.write(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {e}")
            return False
        
        if not documents:
            st.warning("âš ï¸ data í´ë”ì— ì²˜ë¦¬í•  docx íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¬¸ì„œ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False
        
        # ë²¡í„° ìŠ¤í† ì–´ì— ì¶”ê°€
        try:
            success = st.session_state.vector_store.update_documents(documents)
            st.write(f"ğŸ” ë²¡í„° ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸ ê²°ê³¼: {success}")
        except Exception as e:
            st.error(f"âŒ ë²¡í„° ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            st.write(f"ğŸ” ì˜¤ë¥˜ ìƒì„¸: {type(e).__name__}: {e}")
            return False
        
        if success:
            st.session_state.indexed_documents = True
            st.success(f"âœ… {len(documents)}ê°œì˜ ë¬¸ì„œ ì²­í¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì¸ë±ì‹±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            # í†µê³„ ì •ë³´ í‘œì‹œ
            stats = st.session_state.document_processor.get_document_stats(documents)
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats['ì´_ë¬¸ì„œìˆ˜'])
            with col2:
                st.metric("ì´ ì²­í¬ ìˆ˜", stats['ì´_ì²­í¬ìˆ˜'])
            with col3:
                st.metric("í‰ê·  ì²­í¬ ê¸¸ì´", f"{stats['í‰ê· _ì²­í¬ê¸¸ì´']} ë¬¸ì")
            with col4:
                st.metric("ì´ ë¬¸ì ìˆ˜", f"{stats['ì´_ë¬¸ììˆ˜']:,}")
            
            return True
        else:
            st.error("âŒ ë¬¸ì„œ ì¸ë±ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            return False

def generate_answer(query: str, search_results: List[Dict]) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€ ìƒì„±"""
    if not search_results:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (íŒŒì¼ëª… ì œì™¸, ë‚´ìš©ë§Œ í¬í•¨)
    context = "\n\n".join([
        result['content']
        for result in search_results
    ])
    
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ì£¼ì–´ì§„ ì¶˜ì²œë¬¸í™”ì› ê·œì • ë¬¸ì„œë“¤ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

**ì§ˆë¬¸:** {query}

**ê´€ë ¨ ê·œì • ë‚´ìš©:**
{context}

**ë‹µë³€ ê°€ì´ë“œë¼ì¸:**
1. ì£¼ì–´ì§„ ê·œì • ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
2. êµ¬ì²´ì ì¸ ì¡°í•­ëª…, ì¡°ë¬¸, í•­ëª© ë“± ê·¼ê±°ê°€ ë˜ëŠ” ì¡°í•­ì€ ëª…í™•íˆ ì¸ìš©í•´ì£¼ì„¸ìš”
3. ì˜ˆ: "ì œ3ì¡° ì œ2í•­ì— ë”°ë¥´ë©´...", "ìš´ì˜ê·œì • ì œ15ì¡°ì—ì„œ..."
4. ì •í™•í•œ ì •ë³´ê°€ ì—†ë‹¤ë©´ "í•´ë‹¹ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
5. ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”
6. íŒŒì¼ëª…ì´ë‚˜ ë¬¸ì„œëª…ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
7. "ì•ˆë…•í•˜ì„¸ìš”", "ì¶˜ì²œë¬¸í™”ì› ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤" ë“±ì˜ ì¸ì‚¬ë§ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
8. ë°”ë¡œ ë‹µë³€ ë‚´ìš©ìœ¼ë¡œ ì‹œì‘í•˜ì„¸ìš”

**ë‹µë³€:**
"""
    
    try:
        response = st.session_state.gemini_model.generate_content(
            prompt,
            generation_config=genai.types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=1000,
                candidate_count=1
            )
        )
        
        return response.text
        
    except Exception as e:
        return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def main():
    """ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜ - Streamlit ê¸°ë³¸ ê¸°ëŠ¥ í™œìš©"""
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    initialize_session_state()
    
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“‹ ì¶˜ì²œë¬¸í™”ì› ê·œì • ê²€ìƒ‰ ì‹œìŠ¤í…œ</h1>
    </div>
    """, unsafe_allow_html=True)
    
    # API í‚¤ í™•ì¸
    openai_api_key, google_api_key = check_api_keys()
    if not openai_api_key or not google_api_key:
        return
    
    # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”
    if not initialize_components(openai_api_key, google_api_key):
        return
    
    # ìŠ¤ë§ˆíŠ¸ ë¬¸ì„œ ì¸ë±ì‹± (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‹¤í–‰)
    if not st.session_state.indexed_documents:
        # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ê°€ ìµœì‹  ìƒíƒœì¸ì§€ í™•ì¸
        if is_vectorstore_up_to_date() and st.session_state.vector_store and st.session_state.vector_store.get_collection_stats().get('ì´_ë¬¸ì„œìˆ˜', 0) > 0:
            # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì‚¬ìš©
            st.session_state.indexed_documents = True
            st.success("âœ… ê¸°ì¡´ ì¸ë±ì‹± ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ ê²€ìƒ‰ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
            # ìƒˆë¡œ ì¸ë±ì‹± í•„ìš”
            with st.spinner("ğŸ“š ë¬¸ì„œë¥¼ ì¸ë±ì‹±í•˜ê³  ìˆìŠµë‹ˆë‹¤... (ìµœì´ˆ 1íšŒ ë˜ëŠ” ë¬¸ì„œ ë³€ê²½ ì‹œ)"):
                success = index_documents()
                if success:
                    save_documents_hash()  # í•´ì‹œ ì €ì¥
                    st.success("âœ… ë¬¸ì„œ ì¸ë±ì‹±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ì´ì œ ê²€ìƒ‰ì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.error("âŒ ë¬¸ì„œ ì¸ë±ì‹±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. data í´ë”ì— docx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # ê²€ìƒ‰ ì„¤ì • ê¸°ë³¸ê°’
    search_k = 5
    similarity_threshold = 0.4
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.subheader("âš™ï¸ ì„¤ì •")
        
        # ì´ˆê¸°í™” ë²„íŠ¼
        if st.button("ğŸ”„ ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™”", use_container_width=True, type="secondary"):
            st.session_state.chat_history = []
            st.success("âœ… ëŒ€í™” ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.rerun()
        
        st.divider()
        
        # ë„ì›€ë§
        st.subheader("ğŸ’¡ ì‚¬ìš© ë°©ë²•")
        st.info("""
        ğŸ’¬ **Streamlit ì±„íŒ… ì¸í„°í˜ì´ìŠ¤**
        
        1. í•˜ë‹¨ ì±„íŒ…ì°½ì— ì§ˆë¬¸ ì…ë ¥
        2. ì—”í„°í‚¤ë¡œ ê²€ìƒ‰ ì‹¤í–‰
        3. ë‹µë³€ì´ ì±„íŒ… í˜•íƒœë¡œ í‘œì‹œ
        4. ëŒ€í™” ê¸°ë¡ ìë™ ëˆ„ì 
        """)
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ (Streamlit ê¸°ë³¸ ì±„íŒ… ê¸°ëŠ¥ ì‚¬ìš©)
    st.subheader("ğŸ’¬ ê·œì • ê²€ìƒ‰ ì±„íŒ…")
    
    # ì±„íŒ… ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.chat_history:
        # ì‚¬ìš©ì ì§ˆë¬¸
        with st.chat_message("user"):
            st.write(message["query"])
        
        # AI ë‹µë³€
        with st.chat_message("assistant"):
            if message["answer"].startswith("ê´€ë ¨ëœ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"):
                st.warning(message["answer"])
            else:
                st.write(message["answer"])
    
    # ì±„íŒ… ì…ë ¥ì°½ (Streamlit ê¸°ë³¸ ê¸°ëŠ¥ - í•˜ë‹¨ ê³ ì •)
    if prompt := st.chat_input("ì¶˜ì²œë¬¸í™”ì› ê·œì •ì— ëŒ€í•´ ì§ˆë¬¸í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ì…ë ¥ ì¦‰ì‹œ í‘œì‹œ
        with st.chat_message("user"):
            st.write(prompt)
        
        # AI ë‹µë³€ ìƒì„± ë° í‘œì‹œ
        with st.chat_message("assistant"):
            if not st.session_state.indexed_documents:
                st.error("ë¬¸ì„œ ì¸ë±ì‹±ì´ ì•„ì§ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                    # ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
                    search_results = st.session_state.vector_store.search_similar_documents(
                        prompt, k=search_k, score_threshold=similarity_threshold
                    )
                    
                    if search_results:
                        # ë‹µë³€ ìƒì„±
                        answer = generate_answer(prompt, search_results)
                        st.write(answer)
                    else:
                        answer = "ê´€ë ¨ëœ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”."
                        st.warning(answer)
                    
                    # ì±„íŒ… ê¸°ë¡ì— ì¶”ê°€
                    st.session_state.chat_history.append({
                        "query": prompt,
                        "answer": answer,
                        "timestamp": time.time()
                    })

if __name__ == "__main__":
    main() 